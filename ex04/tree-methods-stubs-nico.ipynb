{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "... # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base classes\n",
    "\n",
    "class Node:\n",
    "    pass\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "    \n",
    "    def find_leaf(self, x):\n",
    "        node = self.root\n",
    "        while hasattr(node, \"feature\"):\n",
    "            j = node.feature\n",
    "            if x[j] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensityTree(Tree):\n",
    "    def __init__(self):\n",
    "        super(DensityTree, self).__init__()\n",
    "        \n",
    "    def train(self, data, prior, n_min=20):\n",
    "        '''\n",
    "        data: the feature matrix for the digit under consideration\n",
    "        prior: the prior probability of this digit\n",
    "        n_min: termination criterion (don't split if a node contains fewer instances)\n",
    "        '''\n",
    "        self.prior = prior\n",
    "        N, D = data.shape\n",
    "        D_try = int(np.sqrt(D)) # number of features to consider for each split decision\n",
    "\n",
    "        # find and remember the tree's bounding box, \n",
    "        # i.e. the lower and upper limits of the training feature set\n",
    "        m, M = np.min(data, axis=0), np.max(data, axis=0)\n",
    "        self.box = m.copy(), M.copy()\n",
    "        \n",
    "        #print(data)\n",
    "        #print(m)\n",
    "        #print(M)\n",
    "        \n",
    "        # identify invalid features and adjust the bounding box\n",
    "        # (If m[j] == M[j] for some j, the bounding box has zero volume, \n",
    "        #  causing divide-by-zero errors later on. We must exclude these\n",
    "        #  features from splitting and adjust the bounding box limits \n",
    "        #  such that invalid features have no effect on the volume.)\n",
    "        valid_features   = np.where(m != M)[0]\n",
    "        invalid_features = np.where(m == M)[0]\n",
    "        M[invalid_features] = m[invalid_features] + 1\n",
    "        \n",
    "        #print(valid_features, D_try)\n",
    "        #print(invalid_features)\n",
    "        #print(valid_features[np.random.choice(len(valid_features), size=D_try, replace=False)])\n",
    "        \n",
    "        \n",
    "        # initialize the root node\n",
    "        self.root.data = data\n",
    "        self.root.box = m.copy(), M.copy()\n",
    "\n",
    "        # build the tree\n",
    "        stack = [self.root]\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            n = node.data.shape[0] # number of instances in present node\n",
    "            #print(n, n_min)\n",
    "            if n >= n_min:\n",
    "                # Call 'make_density_split_node()' with 'D_try' randomly selected \n",
    "                # indices from 'valid_features'. This turns 'node' into a split node\n",
    "                # and returns the two children, which must be placed on the 'stack'.\n",
    "                if len(valid_features) < D_try:\n",
    "                    print(\">\")\n",
    "                selected_indices = valid_features[np.random.choice(len(valid_features), size=D_try, replace=False)]\n",
    "                children = make_density_split_node(node, N, selected_indices)\n",
    "                stack.extend(children)\n",
    "            else:\n",
    "                # Call 'make_density_leaf_node()' to turn 'node' into a leaf node.\n",
    "                make_density_leaf_node(node, N)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        leaf = self.find_leaf(x)\n",
    "        # return p(x | y) * p(y) if x is within the tree's bounding box \n",
    "        # and return 0 otherwise\n",
    "        if (x >= self.box[0]).all() and (x <= self.box[1]).all():\n",
    "            #print(leaf.__dict__)\n",
    "            return leaf.response * self.prior\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n",
      "16.0\n",
      "7.5\n",
      "14.0\n",
      "1.5\n",
      "16.0\n",
      "2.5\n",
      "16.0\n",
      "2.5\n",
      "16.0\n",
      "8.5\n",
      "16.0\n",
      "10.0\n",
      "16.0\n",
      "11.5\n",
      "16.0\n",
      "10.5\n",
      "11.0\n",
      "2.5\n",
      "16.0\n",
      "1.5\n",
      "16.0\n",
      "1.5\n",
      "10.0\n",
      "1.5\n",
      "12.0\n",
      "1.5\n",
      "15.0\n",
      "2.0\n",
      "7.0\n",
      "1.5\n",
      "11.0\n",
      "1.5\n",
      "16.0\n",
      "4.5\n",
      "16.0\n",
      "1.5\n",
      "16.0\n",
      "7.5\n",
      "10.0\n",
      "1.5\n",
      "16.0\n",
      "8.5\n",
      "16.0\n",
      "8.5\n",
      "14.0\n",
      "1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nwolf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\nwolf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\nwolf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\nwolf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\nwolf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\nwolf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\nwolf\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-7f8ad35d60fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mdata_digit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m#print(data_digit.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mdensity_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_digit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_digit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdensity_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-86-4080540c08ae>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, prior, n_min)\u001b[0m\n\u001b[0;32m     53\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\">\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[0mselected_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mD_try\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                 \u001b[0mchildren\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_density_split_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m                 \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-102-8ebca5268c56>\u001b[0m in \u001b[0;36mmake_density_split_node\u001b[1;34m(node, N, feature_indices)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# initialize 'left' and 'right' with the data subsets and bounding boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# according to the optimal split found above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj_min\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mt_min\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# store data in left node -- for subsequent splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# train forests (with 20 trees per forest), plot training error confusion matrices, and comment on your results\n",
    "#... # your code here\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.keys())\n",
    "\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]\n",
    "\n",
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "trees = []\n",
    "for i in range(10):\n",
    "    density_tree = DensityTree()\n",
    "    data_digit = data[target == i]\n",
    "    #print(data_digit.shape)\n",
    "    density_tree.train(data_digit, data_digit.shape[0] / len(target))\n",
    "    trees.append(density_tree)\n",
    "    \n",
    "    #print(density_tree.predict(data[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_density_split_node(node, N, feature_indices):\n",
    "    '''\n",
    "    node: the node to be split\n",
    "    N:    the total number of training instances for the current class\n",
    "    feature_indices: a numpy array of length 'D_try', containing the feature \n",
    "                     indices to be considered in the present split\n",
    "    '''\n",
    "    n, D = node.data.shape\n",
    "    m, M = node.box\n",
    "    \n",
    "    V = np.prod(M - m)\n",
    "    #print(V)\n",
    "    \n",
    "    # find best feature j (among 'feature_indices') and best threshold t for the split\n",
    "    e_min = float(\"inf\")\n",
    "    j_min, t_min = None, None\n",
    "    \n",
    "    for j in feature_indices:\n",
    "        # Hint: For each feature considered, first remove duplicate feature values using \n",
    "        # 'np.unique()'. Describe here why this is necessary.\n",
    "        data_unique = np.sort(np.unique(node.data[:, j]))\n",
    "        # Compute candidate thresholds\n",
    "        tj = np.convolve(data_unique, np.ones(2), mode='valid')/2\n",
    "                \n",
    "        \n",
    "        # Illustration: for loop - hint: vectorized version is possible\n",
    "        for t in tj:\n",
    "            # Compute the error\n",
    "            \n",
    "            mask = data_unique < t\n",
    "            # left:\n",
    "            left = data_unique[mask]\n",
    "            V_left = V / (M[j] - m[j]) * (t - m[j])\n",
    "            N_left = len(left)\n",
    "            loo_error_left = N_left/(N*V_left) * (N_left/N - 2*((N_left - 1)/(N - 1)))\n",
    "            \n",
    "            right = data_unique[~mask]\n",
    "            V_right = V / (M[j] - m[j]) * (M[j] - t)\n",
    "            N_right = len(right)\n",
    "            loo_error_right = N_right/(N*V_right) * (N_right/N - 2*((N_right - 1)/(N - 1)))\n",
    "            \n",
    "            loo_error = loo_error_left + loo_error_right\n",
    "            #print(loo_error)\n",
    "            \n",
    "            # choose the best threshold that\n",
    "            if loo_error < e_min:\n",
    "                e_min = loo_error\n",
    "                j_min = j\n",
    "                t_min = t\n",
    "\n",
    "    # create children\n",
    "    left = Node()\n",
    "    right = Node()\n",
    "    \n",
    "    # initialize 'left' and 'right' with the data subsets and bounding boxes\n",
    "    # according to the optimal split found above\n",
    "    mask = node.data[:, j_min] < t_min\n",
    "    \n",
    "    left.data = node.data[mask] # store data in left node -- for subsequent splits\n",
    "    left.box = m, M # store bounding box in left node\n",
    "    left.box[1][j_min] = t_min\n",
    "    \n",
    "    \n",
    "    right.data = node.data[~mask]\n",
    "    right.box = m, M\n",
    "    right.box[0][j_min] = t_min\n",
    "\n",
    "    #print(j_min, t_min)\n",
    "    \n",
    "    # turn the current 'node' into a split node\n",
    "    # (store children and split condition)\n",
    "    node.left = left\n",
    "    node.right = right\n",
    "    node.feature = j_min\n",
    "    node.threshold = t_min\n",
    "\n",
    "    # return the children (to be placed on the stack)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_density_leaf_node(node, N):\n",
    "    '''\n",
    "    node: the node to become a leaf\n",
    "    N:    the total number of training instances for the current class\n",
    "    '''\n",
    "    # compute and store leaf response\n",
    "    n = node.data.shape[0]\n",
    "    v = np.prod(node.box[1] - node.box[0])\n",
    "    node.response = n/(N*v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTree(Tree):\n",
    "    def __init__(self):\n",
    "        super(DecisionTree, self).__init__()\n",
    "        \n",
    "    def train(self, data, labels, n_min=20):\n",
    "        '''\n",
    "        data: the feature matrix for all digits\n",
    "        labels: the corresponding ground-truth responses\n",
    "        n_min: termination criterion (don't split if a node contains fewer instances)\n",
    "        '''\n",
    "        N, D = data.shape\n",
    "        D_try = int(np.sqrt(D)) # how many features to consider for each split decision\n",
    "\n",
    "        # initialize the root node\n",
    "        self.root.data = data\n",
    "        self.root.labels = labels\n",
    "        \n",
    "        stack = [self.root]\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            n = node.data.shape[0] # number of instances in present node\n",
    "            if n >= n_min and not node_is_pure(node):\n",
    "                # Call 'make_decision_split_node()' with 'D_try' randomly selected \n",
    "                # feature indices. This turns 'node' into a split node\n",
    "                # and returns the two children, which must be placed on the 'stack'.\n",
    "                ... # your code here\n",
    "            else:\n",
    "                # Call 'make_decision_leaf_node()' to turn 'node' into a leaf node.\n",
    "                ... # your code here\n",
    "                \n",
    "    def predict(self, x):\n",
    "        leaf = self.find_leaf(x)\n",
    "        # compute p(y | x)\n",
    "        return ... # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_decision_split_node(node, feature_indices):\n",
    "    '''\n",
    "    node: the node to be split\n",
    "    feature_indices: a numpy array of length 'D_try', containing the feature \n",
    "                     indices to be considered in the present split\n",
    "    '''\n",
    "    n, D = node.data.shape\n",
    "\n",
    "    # find best feature j (among 'feature_indices') and best threshold t for the split\n",
    "    ... # your code here\n",
    "\n",
    "    # create children\n",
    "    left = Node()\n",
    "    right = Node()\n",
    "    \n",
    "    # initialize 'left' and 'right' with the data subsets and labels\n",
    "    # according to the optimal split found above\n",
    "    left.data = ... # data in left node\n",
    "    left.labels = ... # corresponding labels\n",
    "    right.data = ...\n",
    "    right.labels = ...\n",
    "\n",
    "    # turn the current 'node' into a split node\n",
    "    # (store children and split condition)\n",
    "    node.left = left\n",
    "    node.right = right\n",
    "    node.feature = ...\n",
    "    node.threshold = ...\n",
    "\n",
    "    # return the children (to be placed on the stack)\n",
    "    return left, right    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_decision_leaf_node(node):\n",
    "    '''\n",
    "    node: the node to become a leaf\n",
    "    '''\n",
    "    # compute and store leaf response\n",
    "    node.N = ...\n",
    "    node.response = ... # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def node_is_pure(node):\n",
    "    '''\n",
    "    check if 'node' ontains only instances of the same digit\n",
    "    '''\n",
    "    return ... # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Density and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# read and prepare the digits data\n",
    "... # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# train trees, plot training error confusion matrices, and comment on your results\n",
    "... # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density and Decision Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class DensityForest():\n",
    "    def __init__(self, n_trees):\n",
    "        # create ensemble\n",
    "        self.trees = [DensityTree() for i in range(n_trees)]\n",
    "    \n",
    "    def train(self, data, prior, n_min=20):\n",
    "        for tree in self.trees:\n",
    "            # train each tree, using a bootstrap sample of the data\n",
    "            ... # your code here\n",
    "\n",
    "    def predict(self, x):\n",
    "        # compute the ensemble prediction\n",
    "        return ... # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class DecisionForest():\n",
    "    def __init__(self, n_trees):\n",
    "        # create ensemble\n",
    "        self.trees = [DecisionTree() for i in range(n_trees)]\n",
    "    \n",
    "    def train(self, data, labels, n_min=0):\n",
    "        for tree in self.trees:\n",
    "            # train each tree, using a bootstrap sample of the data\n",
    "            ... # your code here\n",
    "\n",
    "    def predict(self, x):\n",
    "        # compute the ensemble prediction\n",
    "        return ... # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Density and Decision Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "# train forests (with 20 trees per forest), plot training error confusion matrices, and comment on your results\n",
    "#... # your code here\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.keys())\n",
    "\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]\n",
    "\n",
    "\n",
    "d = DensityTree()\n",
    "ones = data[target==1]\n",
    "prior_one = ones.shape[0] / len(target)\n",
    "d.train(data[target==1], prior_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
