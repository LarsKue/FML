{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4a\n",
    "#### Lars Kühmichel, Nicolas Wolf\n",
    "\n",
    "## 2 Red Cards Study\n",
    "\n",
    "### 2.1 Loading and Cleaning the Data\n",
    "\n",
    "#### What do the feature names stand for?\n",
    "\n",
    "What the feature names stand for can be found in the `README.txt`.\n",
    "E.g. `games` stands for \"number of games in the player-referee\",\n",
    "i.e. how many games that player played under that referee.\n",
    "\n",
    "#### Which irrelevant features might be dropped?\n",
    "Features that are irrelevant are for example `birthday`, `height` or `weight`.\n",
    "Features like `games` and `redCards` are essential to the study,\n",
    "but even features like `refNum` are important to adjust\n",
    "for individual referee bias.\n",
    "\n",
    "#### What relevant features might be missing, but can be computed?\n",
    "\n",
    "One example is the total number of red cards, given by `yellowReds + redCards`.\n",
    "\n",
    "\n",
    "#### Are there missing data values, and how should they be dealt with?\n",
    "\n",
    "Some features, especially skin color ratings, are occasionally missing. We will disaggregate the data to\n",
    "deal with these in a simpler way. We drop dyads that have missing color ratings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from uncertainties import ufloat\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Disaggregating the data\n",
    "\n",
    "The data is more usable in a format that has each instance (line) as a single player-ref interaction.\n",
    "See [this notebook](https://nbviewer.jupyter.org/github/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     playerShort         player             club leagueCountry    birthday  \\\n0  lucas-wilchez  Lucas Wilchez    Real Zaragoza         Spain  31.08.1983   \n1     john-utaka     John Utaka  Montpellier HSC        France  08.01.1982   \n2    abdon-prats    Abdón Prats     RCD Mallorca         Spain  17.12.1992   \n3     pablo-mari     Pablo Marí     RCD Mallorca         Spain  31.08.1993   \n4     ruben-pena     Rubén Peña  Real Valladolid         Spain  18.07.1991   \n5   aaron-hughes   Aaron Hughes        Fulham FC       England  08.11.1979   \n\n   height  weight              position  games  victories  ties  defeats  \\\n0   177.0    72.0  Attacking Midfielder      1          0     0        1   \n1   179.0    82.0          Right Winger      1          0     0        1   \n2   181.0    79.0                   NaN      1          0     1        0   \n3   191.0    87.0           Center Back      1          1     0        0   \n4   172.0    70.0      Right Midfielder      1          1     0        0   \n5   182.0    71.0           Center Back      1          0     0        1   \n\n   goals  \n0      0  \n1      0  \n2      0  \n3      0  \n4      0  \n5      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>playerShort</th>\n      <th>player</th>\n      <th>club</th>\n      <th>leagueCountry</th>\n      <th>birthday</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>position</th>\n      <th>games</th>\n      <th>victories</th>\n      <th>ties</th>\n      <th>defeats</th>\n      <th>goals</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lucas-wilchez</td>\n      <td>Lucas Wilchez</td>\n      <td>Real Zaragoza</td>\n      <td>Spain</td>\n      <td>31.08.1983</td>\n      <td>177.0</td>\n      <td>72.0</td>\n      <td>Attacking Midfielder</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>john-utaka</td>\n      <td>John Utaka</td>\n      <td>Montpellier HSC</td>\n      <td>France</td>\n      <td>08.01.1982</td>\n      <td>179.0</td>\n      <td>82.0</td>\n      <td>Right Winger</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abdon-prats</td>\n      <td>Abdón Prats</td>\n      <td>RCD Mallorca</td>\n      <td>Spain</td>\n      <td>17.12.1992</td>\n      <td>181.0</td>\n      <td>79.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pablo-mari</td>\n      <td>Pablo Marí</td>\n      <td>RCD Mallorca</td>\n      <td>Spain</td>\n      <td>31.08.1993</td>\n      <td>191.0</td>\n      <td>87.0</td>\n      <td>Center Back</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ruben-pena</td>\n      <td>Rubén Peña</td>\n      <td>Real Valladolid</td>\n      <td>Spain</td>\n      <td>18.07.1991</td>\n      <td>172.0</td>\n      <td>70.0</td>\n      <td>Right Midfielder</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>aaron-hughes</td>\n      <td>Aaron Hughes</td>\n      <td>Fulham FC</td>\n      <td>England</td>\n      <td>08.11.1979</td>\n      <td>182.0</td>\n      <td>71.0</td>\n      <td>Center Back</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def disaggregate(filepath, out_path):\n",
    "    \"\"\"\n",
    "    This code was copied and converted to Python 3 from disaggregate_v3.py\n",
    "    Some of it is of questionable quality. Blame the original devs.\n",
    "    see https://osf.io/w7tds/\n",
    "    \"\"\"\n",
    "    dataframe = pd.read_csv(filepath)\n",
    "\n",
    "    # add new vars\n",
    "    dataframe[\"skintone\"] = (dataframe[\"rater1\"] + dataframe[\"rater2\"]) / 2\n",
    "    dataframe[\"all_reds\"] = dataframe[\"yellowReds\"] + dataframe[\"redCards\"]\n",
    "    dataframe[\"all_reds_strict\"] = dataframe[\"redCards\"]\n",
    "    dataframe[\"ref_count\"] = 0\n",
    "\n",
    "    # add a column which tracks how many games each ref is involved in\n",
    "    refs = pd.unique(dataframe[\"refNum\"].values.ravel())  # list all unique ref IDs\n",
    "\n",
    "    # for each ref, count their dyads\n",
    "    print(\"Counting dyads\")\n",
    "    for r in refs:\n",
    "        m = dataframe[\"refNum\"] == r\n",
    "        dataframe[\"ref_count\"][m] = len(dataframe[m])\n",
    "\n",
    "    colnames = list(dataframe.columns)\n",
    "\n",
    "    print(\"creating out\")\n",
    "    j = 0\n",
    "    out = [0 for _ in range(sum(dataframe[\"games\"]))]\n",
    "    for _, row in dataframe.iterrows():\n",
    "        n = row[\"games\"]\n",
    "        c = row[\"all_reds\"]\n",
    "        d = row[\"all_reds_strict\"]\n",
    "\n",
    "        for _ in range(n):\n",
    "            row[\"all_reds\"] = 1 if (c-_) > 0 else 0\n",
    "            row[\"all_reds_strict\"] = 1 if (d-_) > 0 else 0\n",
    "            rowlist = list(row)\n",
    "            out[j] = rowlist\n",
    "            j += 1\n",
    "            if j % 10000 == 0:\n",
    "                print(f\"Number {j} of {dataframe.shape[0]}\")\n",
    "\n",
    "    pd.DataFrame(out, columns=colnames).to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "filepath = Path(\"data\", \"dataset\", \"crowdstorm_disaggregated.csv\")\n",
    "\n",
    "if not filepath.is_file():\n",
    "    print(\"Creating disaggregated dataset...\")\n",
    "    p = Path(\"data\", \"dataset\", \"CrowdstormingDataJuly1st.csv\")\n",
    "    disaggregate(p, filepath)\n",
    "\n",
    "if not filepath.is_file():\n",
    "    raise RuntimeError(\"Could not create disaggregated dataset.\")\n",
    "\n",
    "dataframe = pd.read_csv(filepath)\n",
    "\n",
    "# show some of the dataframe\n",
    "dataframe.iloc[0:6,0:13]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Transforming categorical features to a one-hot encoding\n",
    "\n",
    "When using the code we decided this is not useful and went with UIDs instead.\n",
    "\n",
    "```\n",
    "\n",
    "def one_hot(a):\n",
    "    \"\"\"\n",
    "    See https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-1-hot-encoded-numpy-array\n",
    "    :param a: Array of categorical features (e.g. league strings)\n",
    "    \"\"\"\n",
    "    _, i = np.unique(a, return_inverse=True)\n",
    "    result = np.full((i.size, i.max() + 1), False)\n",
    "    result[np.arange(i.size),i] = True\n",
    "\n",
    "    return result\n",
    "\n",
    "# for some reason pandas only accepts these as 2d if they are lists, not numpy arrays\n",
    "dataframe.club = list(one_hot(dataframe.club.fillna(\"\")))\n",
    "dataframe.leagueCountry = list(one_hot(dataframe.leagueCountry.fillna(\"\")))\n",
    "dataframe.position = list(one_hot(dataframe.position.fillna(\"\")))\n",
    "\n",
    "# print some samples to show this worked\n",
    "print(\"club\")\n",
    "print(dataframe.club[0])\n",
    "print(\"leagueCountry\")\n",
    "print(dataframe.leagueCountry[0])\n",
    "print(\"position\")\n",
    "print(dataframe.position[0])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Transforming categorical features to unique IDs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def uid(a):\n",
    "    _, i = np.unique(a, return_inverse=True)\n",
    "    return i\n",
    "\n",
    "dataframe.club = list(uid(dataframe.club.fillna(\"\")))\n",
    "dataframe.leagueCountry = list(uid(dataframe.leagueCountry.fillna(\"\")))\n",
    "dataframe.position = list(uid(dataframe.position.fillna(\"\")))\n",
    "\n",
    "# print some samples to show this worked\n",
    "print(\"club\")\n",
    "print(dataframe.club[0])\n",
    "print(\"leagueCountry\")\n",
    "print(dataframe.leagueCountry[0])\n",
    "print(\"position\")\n",
    "print(dataframe.position[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Distribution of individual ref-player dyad game numbers\n",
    "\n",
    "See again [this notebook](https://nbviewer.jupyter.org/github/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb#What-is-the-distribution-of-individual-ref-player-dyad-game-numbers?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# distribution of individual ref-player dyad game numbers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(dataframe.games, bins=max(dataframe.games), histtype=\"stepfilled\")\n",
    "axes[0].set_xlabel(\"Number of Interactions\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "axes[1].hist(dataframe.games, bins=max(dataframe.games), histtype=\"stepfilled\")\n",
    "axes[1].set_yscale(\"symlog\")\n",
    "axes[1].set_title(\"Log Scaled\")\n",
    "axes[1].set_xlabel(\"Number of Interactions\")\n",
    "axes[1].set_ylabel(\"Log Frequency\")\n",
    "\n",
    "fig.suptitle(\"Distribution of Individual Ref-Player Dyad Game Numbers\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Do the Raters agree on skin colour ratings?\n",
    "\n",
    "The raters agree with one another in $76.8\\%$ of cases.\n",
    "When they disagree, they still typically pick neighbouring categories.\n",
    "It is therefore useful to take the mean of the two raters since they disagree relatively often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "rater1 = np.array(dataframe.rater1)\n",
    "rater2 = np.array(dataframe.rater2)\n",
    "\n",
    "# remove nan values. Here, it is important to remove associated dyads from both raters\n",
    "mask1 = ~np.isnan(rater1)\n",
    "mask2 = ~np.isnan(rater2)\n",
    "mask = mask1 & mask2\n",
    "rater1 = rater1[mask]\n",
    "rater2 = rater2[mask]\n",
    "\n",
    "nagree = np.sum(rater1 == rater2)\n",
    "diff = rater1 - rater2\n",
    "\n",
    "print(f\"Number of times raters agree: {nagree}\")\n",
    "print(f\"Number of times raters disagree: {len(diff) - nagree}\")\n",
    "print(f\"Raters agree in {100 * nagree / len(diff):.2f}% of cases.\")\n",
    "\n",
    "_df = pd.DataFrame(pd.Series(diff).value_counts(), columns=[\"Counts\"])\n",
    "_df.index.name = \"Difference\"\n",
    "\n",
    "_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Comparison of Raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# bar charts are slow (because they need np.unique counts),\n",
    "# so we will use a hack to generate something equivalent\n",
    "values = np.array([0.0, 0.25, 0.50, 0.75, 1.0])\n",
    "width = 0.05\n",
    "epsilon = 0.000001\n",
    "\n",
    "bins1 = np.array(list(zip(values - width, values + epsilon))).flatten()\n",
    "bins2 = np.array(list(zip(values - epsilon, values + width))).flatten()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dataframe.rater1, bins=bins1, label=\"Rater 1\")\n",
    "plt.hist(dataframe.rater2, bins=bins2, label=\"Rater 2\")\n",
    "plt.xticks(values)\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Raters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Where do raters disagree most?\n",
    "\n",
    "From the plots it is evident that the two raters disagree most on lighter skin colors. The most common case\n",
    "where they disagree has Rater 1 select the skintone as \"Very Light\" $(0.0)$ and Rater 2 as \"Light\" $(0.25)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "mask = rater1 != rater2\n",
    "\n",
    "r1d = rater1[mask]\n",
    "r2d = rater2[mask]\n",
    "\n",
    "bins = np.array(list(zip(values - width, values + width))).flatten()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].hist(r1d, bins=bins, color=\"C0\")\n",
    "axes[0].set_title(\"Rater 1\")\n",
    "axes[0].set_xticks(values)\n",
    "axes[0].set_xlabel(\"Rating\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[1].hist(r2d, bins=bins, color=\"C1\")\n",
    "axes[1].set_title(\"Rater 2\")\n",
    "axes[1].set_xticks(values)\n",
    "axes[1].set_xlabel(\"Rating\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "fig.suptitle(\"Skin Color Ratings on Cases where Raters Disagree\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "pd.crosstab(dataframe[\"rater1\"], dataframe[\"rater2\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Should Referees with very few appearances be excluded from the dataset?\n",
    "\n",
    "Since we disagreggated the data, an \"appearance\" is now a single dyad.\n",
    "Excluding referees with few appearances is generally a good idea,\n",
    "if we have enough referees with many appearances,\n",
    "such as to not skew the dataset through outliers. [This notebook](https://nbviewer.jupyter.org/github/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb#We-clean-the-data-by-excluding-interactions-by-refs-who-feature-in-fewer-than-22-dyads)\n",
    "mentions that referees with fewer than 22 appearances did not play in\n",
    "one of the major leagues we are interested in, and should thus be removed.\n",
    "\n",
    "#### What does the distribution of ref occurance look like?\n",
    "\n",
    "See again [this notebook](https://nbviewer.jupyter.org/github/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb#And-what-does-the-distribution-of-ref-occurance-look-like?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_refs = dataframe.refNum.value_counts()\n",
    "\n",
    "num_refs = len(all_refs)\n",
    "print(\"Total number of referees =\", num_refs)\n",
    "print(\"Median number of dyads per referee =\", np.median(dataframe.refNum.value_counts()))\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=1, figsize=(12, 4))\n",
    "axes.hist(dataframe.refNum.value_counts().tolist(), bins=num_refs, edgecolor=\"black\", linewidth=0.3)\n",
    "axes.set_xscale(\"symlog\") # symetric log scale\n",
    "axes.set_yscale(\"symlog\")\n",
    "axes.set_title(\"Referee occurance, log scaled\")\n",
    "axes.set_xlabel(\"log (number of occurances)\")\n",
    "axes.set_ylabel(\"log (frequency)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### We clean the data by excluding interactions by refs who feature in fewer than 22 dyads\n",
    "\n",
    "See again [this notebook](https://nbviewer.jupyter.org/github/mathewzilla/redcard/blob/master/Crowdstorming_visualisation.ipynb#We-clean-the-data-by-excluding-interactions-by-refs-who-feature-in-fewer-than-22-dyads).\n",
    "\n",
    "We keep only about $40\\%$ of referees, but more than $97\\%$ of dyads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "good_refs = all_refs[all_refs>21]\n",
    "\n",
    "print(f\"Referees kept: {len(good_refs)} out of {len(all_refs)} ({100 * len(good_refs) / len(all_refs):.2f}%)\")\n",
    "print(f\"Dyads kept: {sum(good_refs)} out of {sum(all_refs)} ({100 * sum(good_refs) / sum(all_refs):.2f}%)\")\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=1, figsize=(12, 4))\n",
    "axes.hist(good_refs.tolist(), num_refs-11, edgecolor=\"black\", linewidth=0.3)\n",
    "axes.set_xscale(\"symlog\") # symetric log scale\n",
    "plt.xlim([1,10000])\n",
    "axes.set_yscale(\"symlog\")\n",
    "plt.ylim([0,1000])\n",
    "axes.set_title(\"Referee occurance following our cull, log scaled\")\n",
    "axes.set_xlabel(\"log (number of occurances)\")\n",
    "axes.set_ylabel(\"log (frequency)\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# apply the filter\n",
    "dataframe = dataframe[dataframe[\"refNum\"].isin(good_refs.index.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Should features be normalized and/or centralized?\n",
    "\n",
    "Centralizing the data is useful for linear regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Model Creation\n",
    "\n",
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegressor:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "        self.beta = None\n",
    "        self.b = None\n",
    "\n",
    "    def func(self, x):\n",
    "        if self.beta is None or self.b is None:\n",
    "            raise RuntimeError(\"Attempted to use regressor weights without fitting.\")\n",
    "        return self.beta * x + self.b\n",
    "\n",
    "    def fit(self, assume_centralized=False):\n",
    "        if not assume_centralized:\n",
    "            mx, my = self.centralize()\n",
    "        else:\n",
    "            mx, my = 0, 0\n",
    "\n",
    "        if self.x.ndim > 1:\n",
    "            self.beta = np.linalg.pinv(self.x) @ self.y\n",
    "            self.b = my - self.beta @ mx\n",
    "        else:\n",
    "            self.beta = np.dot(self.x, self.y) / np.sum(np.square(self.x))\n",
    "            self.b = my - self.beta * mx\n",
    "\n",
    "        return self.beta, self.b\n",
    "\n",
    "    def centralize(self):\n",
    "        mx = np.mean(self.x, axis=0)\n",
    "        my = np.mean(self.y, axis=0)\n",
    "        self.x = self.x - mx\n",
    "        self.y = self.y - my\n",
    "        return mx, my\n",
    "\n",
    "\n",
    "def lr_tones(df):\n",
    "    tones = np.unique(df.skintone.dropna())\n",
    "\n",
    "    sumgames = []\n",
    "    sumreds = []\n",
    "\n",
    "    for tone in tones:\n",
    "        mask = df.skintone == tone\n",
    "        games = np.sum(df.games[mask])\n",
    "        reds = np.sum(df.all_reds[mask])\n",
    "\n",
    "        sumgames.append(games)\n",
    "        sumreds.append(reds)\n",
    "\n",
    "    sumgames = np.array(sumgames)\n",
    "    sumreds = np.array(sumreds)\n",
    "\n",
    "    expected = np.sum(sumreds) / np.sum(sumgames)\n",
    "\n",
    "    lr = LinearRegressor(tones, sumreds / sumgames)\n",
    "    lr.fit()\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.bar(tones, sumreds / sumgames, label=\"actual\", width=0.1, edgecolor=\"black\", lw=0.2)\n",
    "    plt.axhline(expected, label=\"expected\", linestyle=\"--\", color=\"black\", alpha=0.8)\n",
    "\n",
    "    left, right = plt.xlim()\n",
    "    trend_x = np.linspace(left, right, 10)\n",
    "    plt.plot(trend_x, lr.func(trend_x), label=\"trend\", color=\"C1\")\n",
    "\n",
    "    plt.xlim(left, right)\n",
    "    plt.xlabel(\"Skin Tone Rating (Mean)\")\n",
    "    plt.ylabel(\"Red Cards per Game\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "lr_tones(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Regression Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    pass\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "    \n",
    "    def find_leaf(self, x):\n",
    "        node = self.root\n",
    "        while hasattr(node, \"feature\"):\n",
    "            j = node.feature\n",
    "            if x[j] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class RegressionTree(Tree):\n",
    "    def __init__(self):\n",
    "        super(RegressionTree, self).__init__()\n",
    "        \n",
    "    def train(self, data, labels, n_min=100):\n",
    "        '''\n",
    "        data: the feature matrix for all digits\n",
    "        labels: the corresponding ground-truth responses\n",
    "        n_min: termination criterion (don't split if a node contains fewer instances)\n",
    "        '''\n",
    "        N, D = data.shape\n",
    "        D_try = int(np.sqrt(D)) # how many features to consider for each split decision\n",
    "\n",
    "        # initialize the root node\n",
    "        self.root.data = data\n",
    "        self.root.labels = labels\n",
    "        \n",
    "        stack = [self.root]\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            n = node.data.shape[0] # number of instances in present node\n",
    "            #print(n)\n",
    "            if n >= n_min:\n",
    "                # Call 'make_decision_split_node()' with 'D_try' randomly selected \n",
    "                # feature indices. This turns 'node' into a split node\n",
    "                # and returns the two children, which must be placed on the 'stack'.\n",
    "                selected_indices = np.random.choice(D, size=D_try, replace=False)\n",
    "                children = make_regression_split_node(node, selected_indices)\n",
    "                if children is None:\n",
    "                    make_regression_leaf_node(node)\n",
    "                else:\n",
    "                    stack.extend(children)\n",
    "            else:\n",
    "                # Call 'make_decision_leaf_node()' to turn 'node' into a leaf node.\n",
    "                make_regression_leaf_node(node)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        leaf = self.find_leaf(x)\n",
    "        # compute p(y | x)\n",
    "        return leaf.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def rolling_mean(x, n):\n",
    "    \"\"\" see https://stackoverflow.com/questions/14313510/how-to-calculate-rolling-moving-average-using-numpy-scipy \"\"\"\n",
    "    return np.convolve(x, np.ones(n), mode=\"valid\") / n\n",
    "\n",
    "def make_regression_split_node(node, feature_indices):\n",
    "    \"\"\"\n",
    "    node: the node to be split\n",
    "    feature_indices: a numpy array of length 'D_try', containing the feature\n",
    "                     indices to be considered in the present split\n",
    "    \"\"\"\n",
    "    n, D = node.data.shape\n",
    "\n",
    "    # find best feature j (among 'feature_indices') and best threshold t for the split\n",
    "    e_min = float(\"inf\")\n",
    "    j_min, t_min = None, None\n",
    "    \n",
    "    for j in feature_indices:\n",
    "        # Hint: For each feature considered, first remove duplicate feature values using \n",
    "        # 'np.unique()'. Describe here why this is necessary.\n",
    "        data_unique = np.sort(np.unique(node.data[:, j]))\n",
    "        \n",
    "        # all points have the same j-th value => can't split\n",
    "        if len(data_unique) == 1:\n",
    "            continue\n",
    "        \n",
    "        # Compute candidate thresholds\n",
    "        tj = rolling_mean(data_unique, 2)\n",
    "        \n",
    "        \n",
    "        # Illustration: for loop - hint: vectorized version is possible\n",
    "        for t in tj:\n",
    "            mask = node.data[:, j] < t\n",
    "            # left:\n",
    "            features_left = node.data[mask]\n",
    "            labels_left = node.labels[mask]\n",
    "            lr_left = LinearRegressor(features_left, labels_left)\n",
    "            popt_left = lr_left.fit()\n",
    "            response_left = np.dot(features_left, popt_left[0]) + popt_left[1]\n",
    "            average_response_left = response_left.sum() / features_left.shape[0]\n",
    "            error_left = ((labels_left - average_response_left)**2).sum()\n",
    "            \n",
    "            \n",
    "            # Right:\n",
    "            features_right = node.data[~mask]\n",
    "            labels_right = node.labels[~mask]\n",
    "            lr_right = LinearRegressor(features_right, labels_right)\n",
    "            popt_right = lr_right.fit()\n",
    "            response_right = np.dot(features_right, popt_right[0]) + popt_right[1]\n",
    "            average_response_right = response_right.sum() / features_right.shape[0]\n",
    "            error_right = ((labels_right - average_response_right)**2).sum()\n",
    "            \n",
    "            \n",
    "            \n",
    "            error = error_left + error_right\n",
    "            \n",
    "            # choose the best threshold that\n",
    "            if error < e_min:\n",
    "                e_min = error\n",
    "                j_min = j\n",
    "                t_min = t\n",
    "\n",
    "                \n",
    "    if t_min is None:\n",
    "        return None\n",
    "        \n",
    "        \n",
    "    # create children\n",
    "    left = Node()\n",
    "    right = Node()\n",
    "    \n",
    "    # initialize 'left' and 'right' with the data subsets and labels\n",
    "    # according to the optimal split found above\n",
    "    mask = node.data[:, j_min] < t_min\n",
    "    \n",
    "    left.data = node.data[mask] # data in left node\n",
    "    left.labels = node.labels[mask] # corresponding labels\n",
    "    right.data = node.data[~mask]\n",
    "    right.labels = node.labels[~mask]\n",
    "\n",
    "    # turn the current 'node' into a split node\n",
    "    # (store children and split condition)\n",
    "    node.left = left\n",
    "    node.right = right\n",
    "    node.feature = j_min\n",
    "    node.threshold = t_min\n",
    "\n",
    "    # return the children (to be placed on the stack)\n",
    "    return left, right    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def make_regression_leaf_node(node):\n",
    "    \"\"\"\n",
    "    node: the node to become a leaf\n",
    "    \"\"\"\n",
    "    # compute and store leaf response\n",
    "    node.N = node.data.shape[0]\n",
    "    \n",
    "    lr = LinearRegressor(node.data, node.labels)\n",
    "    popt = lr.fit()\n",
    "    response = np.dot(node.data, popt[0]) + popt[1]\n",
    "    node.response = response.sum() / node.data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class RegressionForest:\n",
    "    def __init__(self, n_trees):\n",
    "        # create ensemble\n",
    "        self.trees = [RegressionTree() for i in range(n_trees)]\n",
    "    \n",
    "    def train(self, data, labels, n_min=100):\n",
    "        N = data.shape[0]\n",
    "        for tree in self.trees:\n",
    "            # train each tree, using a bootstrap sample of the data\n",
    "            training_set_indices = np.random.choice(N, size=N, replace=True)\n",
    "            tree.train(data[training_set_indices], labels[training_set_indices])\n",
    "\n",
    "    def predict(self, x):\n",
    "        # compute the ensemble prediction\n",
    "        return np.mean([tree.predict(x) for tree in self.trees])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Cross-Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x = np.stack([dataframe.skintone.values], axis=1)\n",
    "y = dataframe.all_reds.values\n",
    "\n",
    "\n",
    "mask = (np.all(~np.isnan(x), axis=1)) & (~np.isnan(y))\n",
    "#mask = (~np.isnan(x)) & (~np.isnan(y))\n",
    "x = x[mask]\n",
    "y = y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class LinearRegressor_Test():\n",
    "    def __init__(self, popt = None):\n",
    "        self.popt = popt\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        lr = LinearRegressor(X_train, Y_train)\n",
    "        self.popt = lr.fit()\n",
    "        \n",
    "    def score(self, X_test, Y_test):\n",
    "        response = np.dot(X_test, self.popt[0]) + self.popt[1]\n",
    "        error = ((Y_test - response)**2).sum() / Y_test.shape[0]\n",
    "        return 1 - error\n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        return {\"popt\": self.popt}\n",
    "    \n",
    "lr_test = LinearRegressor_Test()\n",
    "scores = cross_val_score(lr_test, x, y, cv=10)\n",
    "print(scores)\n",
    "print(f\"score = {np.mean(scores):0.3f} +- {np.std(scores):0.3f}\")\n",
    "print(f\"error = {1-np.mean(scores):0.3f} +- {np.std(scores):0.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class RegressionForest_Test():\n",
    "    def __init__(self, forest = None):\n",
    "        self.forest = forest\n",
    "    \n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.forest = RegressionForest(10)\n",
    "        self.forest.train(X_train, Y_train)\n",
    "        \n",
    "    def score(self, X_test, Y_test):\n",
    "        response = [self.forest.predict(x) for x in X_test]\n",
    "        error = ((Y_test - response)**2).sum() / Y_test.shape[0]\n",
    "        return 1 - error\n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        return {\"forest\": self.forest}\n",
    "    \n",
    "rf_test = RegressionForest_Test()\n",
    "scores = cross_val_score(rf_test, x, y, cv=10)\n",
    "print(scores)\n",
    "print(f\"score = {np.mean(scores):0.3f} +- {np.std(scores):0.3f}\")\n",
    "print(f\"error = {1-np.mean(scores):0.3f} +- {np.std(scores):0.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Answering the Research Question\n",
    "\n",
    "From this test, we cannot conclude that\n",
    "there is a skin color bias in red card\n",
    "decisions, since these datasets do not\n",
    "exhibit higher test errors than the original\n",
    "unscattered dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skintone_original = np.stack([dataframe.skintone.values], axis=1)\n",
    "reds_original = dataframe.all_reds.values\n",
    "mask = (np.all(~np.isnan(skintone_original), axis=1)) & (~np.isnan(reds_original))\n",
    "skintone_original = skintone_original[mask]\n",
    "reds_original = reds_original[mask]\n",
    "\n",
    "for i in range(19):\n",
    "    skintone = skintone_original[np.random.permutation(skintone_original.shape[0])]\n",
    "\n",
    "    lr_test = LinearRegressor_Test()\n",
    "    scores = cross_val_score(lr_test, skintone, reds_original, cv=10)\n",
    "    print(f\"{i+1}\\tscore = {np.mean(scores):0.3f} +- {np.std(scores):0.3f}\")\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skintone_original = np.stack([dataframe.skintone.values], axis=1)\n",
    "reds_original = dataframe.all_reds.values\n",
    "mask = (np.all(~np.isnan(skintone_original), axis=1)) & (~np.isnan(reds_original))\n",
    "skintone_original = skintone_original[mask]\n",
    "reds_original = reds_original[mask]\n",
    "\n",
    "for i in range(19):\n",
    "    skintone = skintone_original[np.random.permutation(skintone_original.shape[0])]\n",
    "\n",
    "    lr_test = RegressionForest_Test()\n",
    "    scores = cross_val_score(lr_test, skintone, reds_original, cv=10)\n",
    "    print(f\"{i+1}\\tscore = {np.mean(scores):0.3f} +- {np.std(scores):0.3f}\")\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.4 How to Lie with Statistics\n",
    "\n",
    "As we have already seen in the previous exercise parts, it is possible to\n",
    "arrive at different conclusions for the dataset depending on which method of\n",
    "data examination is used. Looking at the total distribution leads to a clear\n",
    "(if small) correlation between skin color and red card decisions, whereas the\n",
    "permutation test tells us there is no significant bias.\n",
    "\n",
    "We have tried several different data cleaning techniques and data set transformations,\n",
    "but were unable to find one that yields a better distinction between conclusions than\n",
    "these two tests."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 Alternative Hypotheses\n",
    "\n",
    "#### Reverse Causation: Dark skinned players generate more red card decisions.\n",
    "\n",
    "Suppose players with dark skin exhibit a more aggressive playstyle overall, which leads\n",
    "to more fouls made. It would be logical for referees to give more red cards to players\n",
    "who foul more.\n",
    "\n",
    "Testing this hypothesis is superfluous as its correlation is equivalent to the original\n",
    "hypothesis. Since we can only make judgments about correlation, we cannot determine\n",
    "if the original hypothesis or this one is \"more correct\".\n",
    "\n",
    "#### Third Cause Fallacy: Both Dark Skin and Red Card Decisions are caused by Hot Weather\n",
    "\n",
    "Suppose referees really hate playing in hot weather, since it is more exhausting, thus\n",
    "giving more red cards because they are annoyed by the weather already.\n",
    "Since countries with hot weather typically have more people with darker skin, more\n",
    "red cards are given to darker skinned players as a result.\n",
    "\n",
    "To test this hypothesis, let's look at the distributions in England (cold weather)\n",
    "vs. Spain (warm weather)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask_england = dataframe.leagueCountry == 0\n",
    "mask_spain = dataframe.leagueCountry == 3\n",
    "\n",
    "dataframe_england = dataframe[mask_england]\n",
    "dataframe_spain = dataframe[mask_spain]\n",
    "\n",
    "def analysis(df):\n",
    "    print(\"Players by skintone:\")\n",
    "    vc = df.skintone.value_counts()\n",
    "    plt.bar(vc.index, vc.values, width=0.1)\n",
    "    plt.show()\n",
    "\n",
    "    print(df.skintone.value_counts())\n",
    "    print(\"Total Red Cards received:\")\n",
    "    print(np.sum(df.all_reds))\n",
    "    print(\"Total Games played:\")\n",
    "    print(np.sum(df.games))\n",
    "    print(\"Red Cards per game:\")\n",
    "    print(np.sum(df.all_reds) / np.sum(df.games))\n",
    "\n",
    "    print(\"Red Cards by Skin Tone:\")\n",
    "    print(pd.crosstab(df.skintone, df.all_reds))\n",
    "\n",
    "analysis(dataframe_england)\n",
    "analysis(dataframe_spain)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see there are more dark skinned players in Spain, and more red cards are given per game,\n",
    "which supports this hypothesis.\n",
    "\n",
    "Let's also look at the red card distributions for each country."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr_tones(dataframe_england)\n",
    "lr_tones(dataframe_spain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is clear bias shown in England whereas there is little to no bias in Spain. That said,\n",
    "this analysis is incomplete as a permutation test would be needed here to check for bias."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tscore = 0.992 +- 0.001\n",
      "2\tscore = 0.992 +- 0.001\n",
      "3\tscore = 0.992 +- 0.001\n",
      "4\tscore = 0.992 +- 0.001\n",
      "5\tscore = 0.992 +- 0.001\n",
      "6\tscore = 0.992 +- 0.001\n",
      "7\tscore = 0.992 +- 0.001\n",
      "8\tscore = 0.992 +- 0.001\n",
      "9\tscore = 0.992 +- 0.001\n",
      "10\tscore = 0.992 +- 0.001\n",
      "11\tscore = 0.992 +- 0.001\n",
      "12\tscore = 0.992 +- 0.001\n",
      "13\tscore = 0.992 +- 0.001\n",
      "14\tscore = 0.992 +- 0.001\n",
      "15\tscore = 0.992 +- 0.001\n",
      "16\tscore = 0.992 +- 0.001\n",
      "17\tscore = 0.992 +- 0.001\n",
      "18\tscore = 0.992 +- 0.001\n",
      "19\tscore = 0.992 +- 0.001\n"
     ]
    }
   ],
   "source": [
    "skintone_original = np.stack([dataframe.skintone.values], axis=1)\n",
    "reds_original = dataframe.all_reds.values\n",
    "mask = (np.all(~np.isnan(skintone_original), axis=1)) & (~np.isnan(reds_original))\n",
    "skintone_original = skintone_original[mask]\n",
    "reds_original = reds_original[mask]\n",
    "\n",
    "for i in range(19):\n",
    "    skintone = skintone_original[np.random.permutation(skintone_original.shape[0])]\n",
    "\n",
    "    lr_test = RegressionForest_Test()\n",
    "    scores = cross_val_score(lr_test, skintone, reds_original, cv=10)\n",
    "    print(f\"{i+1}\\tscore = {np.mean(scores):0.3f} +- {np.std(scores):0.3f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}