{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_1(x):\n",
    "    return 2*x-x**2   #Y=0\n",
    "\n",
    "def cumulative_2(x):\n",
    "    return x**2       #Y=1\n",
    "\n",
    "def cumulative_1_inv(x):\n",
    "    return 1 - math.sqrt(1-x)\n",
    "\n",
    "def cumulative_2_inv(x):\n",
    "    return math.sqrt(x)\n",
    "\n",
    "def create_data(N):\n",
    "    y = np.random.choice(2, N)\n",
    "    x = np.zeros(N)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        if y[i] == 1:\n",
    "            z = np.random.random(1)\n",
    "            x[i] = cumulative_1_inv(z)\n",
    "            i = i + 1\n",
    "        elif y[i] == 0:\n",
    "            z = np.random.random(1)\n",
    "            x[i] = cumulative_2_inv(z)\n",
    "            i = i + 1\n",
    "    return x, y\n",
    "\n",
    "def error_a(x_t):\n",
    "    return 1/4 + (x_t - 1/2)**2\n",
    "\n",
    "def error_b(x_t):\n",
    "    return 3/4 - (x_t - 1/2)**2\n",
    "\n",
    "def a_1(x, x_t):\n",
    "    if x > x_t:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def b_1(x, x_t):\n",
    "    if x < x_t:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def error_rate(x, y):\n",
    "    i = 0\n",
    "    z = np.zeros(len(x))\n",
    "    while i < len(x):\n",
    "        if x[i] == y[i]:\n",
    "            z[i] = 1\n",
    "            i = i + 1\n",
    "        else:\n",
    "            z[i] = 0\n",
    "            i = i + 1\n",
    "    return np.mean(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_comparison_a(N, x_t):\n",
    "    b = create_data(N)\n",
    "    x_values = b[0]\n",
    "    real_y = np.zeros(len(x_values))\n",
    "    guessed_y = np.zeros(len(x_values))\n",
    "\n",
    "    i = 0\n",
    "    while i < len(x_values):\n",
    "        real_y[i] = np.random.choice([1,0], p=[1-x_values[i], x_values[i]])\n",
    "        i = i + 1\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(x_values):\n",
    "        guessed_y[i] = a_1(x_values[i], x_t)\n",
    "        i = i + 1\n",
    "    \n",
    "    return error_rate(real_y, guessed_y)\n",
    "\n",
    "def error_comparison_b(N, x_t):\n",
    "    b = create_data(N)\n",
    "    x_values = b[0]\n",
    "    real_y = np.zeros(len(x_values))\n",
    "    guessed_y = np.zeros(len(x_values))\n",
    "\n",
    "    i = 0\n",
    "    while i < len(x_values):\n",
    "        real_y[i] = np.random.choice([1,0], p=[1-x_values[i], x_values[i]])\n",
    "        i = i + 1\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(x_values):\n",
    "        guessed_y[i] = b_1(x_values[i], x_t)\n",
    "        i = i + 1\n",
    "    \n",
    "    return error_rate(real_y, guessed_y)\n",
    "\n",
    "def error_comparison_c(N, x_t):\n",
    "    b = create_data(N)\n",
    "    x_values = b[0]\n",
    "    real_y = np.zeros(len(x_values))\n",
    "    guessed_y = np.zeros(len(x_values))\n",
    "\n",
    "    i = 0\n",
    "    while i < len(x_values):\n",
    "        real_y[i] = np.random.choice([1,0], p=[1-x_values[i], x_values[i]])\n",
    "        i = i + 1\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(x_values):\n",
    "        guessed_y[i] = np.random.choice(2)\n",
    "        i = i + 1\n",
    "    \n",
    "    return error_rate(real_y, guessed_y)\n",
    "\n",
    "def error_comparison_d(N, x_t):\n",
    "    b = create_data(N)\n",
    "    x_values = b[0]\n",
    "    real_y = np.zeros(len(x_values))\n",
    "    guessed_y = np.zeros(len(x_values))\n",
    "\n",
    "    i = 0\n",
    "    while i < len(x_values):\n",
    "        real_y[i] = np.random.choice([1,0], p=[1-x_values[i], x_values[i]])\n",
    "        i = i + 1\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(x_values):\n",
    "        guessed_y[i] = 1\n",
    "        i = i + 1\n",
    "    \n",
    "    return error_rate(real_y, guessed_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2_a(N, x_t):\n",
    "    i = 0\n",
    "    z = np.zeros(11)\n",
    "    while i < 11:\n",
    "        z[i] = error_comparison_a(N, x_t)\n",
    "        i = i + 1\n",
    "    \n",
    "    print(\"Test set size: \", N)\n",
    "    print(\"Standard deviation of the error: \", np.std(z))\n",
    "    print(\"Mean error: \", np.mean(z))\n",
    "    print(\"Theoretical error rate: \", error_a(x_t))\n",
    "    print(\"\")\n",
    "    \n",
    "def task_2_b(N, x_t):\n",
    "    i = 0\n",
    "    z = np.zeros(11)\n",
    "    while i < 11:\n",
    "        z[i] = error_comparison_b(N, x_t)\n",
    "        i = i + 1\n",
    "    \n",
    "    print(\"Test set size: \", N)\n",
    "    print(\"Standard deviation of the error: \", np.std(z))\n",
    "    print(\"Mean error: \", np.mean(z))\n",
    "    print(\"Theoretical error rate: \", error_b(x_t))\n",
    "    print(\"\")\n",
    "    \n",
    "def task_3_c(N, x_t):\n",
    "    i = 0\n",
    "    z = np.zeros(11)\n",
    "    while i < 11:\n",
    "        z[i] = error_comparison_c(N, x_t)\n",
    "        i = i + 1\n",
    "    \n",
    "    print(\"Test set size: \", N)\n",
    "    print(\"Standard deviation of the error: \", np.std(z))\n",
    "    print(\"Mean error: \", np.mean(z))\n",
    "    print(\"Theoretical error rate: \", 1/2)\n",
    "    print(\"\")\n",
    "    \n",
    "def task_3_d(N, x_t):\n",
    "    i = 0\n",
    "    z = np.zeros(11)\n",
    "    while i < 11:\n",
    "        z[i] = error_comparison_d(N, x_t)\n",
    "        i = i + 1\n",
    "    \n",
    "    print(\"Test set size: \", N)\n",
    "    print(\"Standard deviation of the error: \", np.std(z))\n",
    "    print(\"Mean error: \", np.mean(z))\n",
    "    print(\"Theoretical error rate: \", 1/2)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size:  10\n",
      "Standard deviation of the error:  0.12128785512842122\n",
      "Mean error:  0.22727272727272727\n",
      "Theoretical error rate:  0.33999999999999997\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.0409998992137443\n",
      "Mean error:  0.34909090909090906\n",
      "Theoretical error rate:  0.33999999999999997\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.01706041767483051\n",
      "Mean error:  0.3348181818181818\n",
      "Theoretical error rate:  0.33999999999999997\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.004472948996721601\n",
      "Mean error:  0.3382\n",
      "Theoretical error rate:  0.33999999999999997\n",
      "\n",
      "Test set size:  10\n",
      "Standard deviation of the error:  0.09958591954639386\n",
      "Mean error:  0.309090909090909\n",
      "Theoretical error rate:  0.25\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.04647935647696079\n",
      "Mean error:  0.2381818181818182\n",
      "Theoretical error rate:  0.25\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.009153421435012276\n",
      "Mean error:  0.2531818181818182\n",
      "Theoretical error rate:  0.25\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.00403593363802956\n",
      "Mean error:  0.24958181818181818\n",
      "Theoretical error rate:  0.25\n",
      "\n",
      "Test set size:  10\n",
      "Standard deviation of the error:  0.09875254992000196\n",
      "Mean error:  0.24545454545454548\n",
      "Theoretical error rate:  0.26\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.03741657386773942\n",
      "Mean error:  0.26\n",
      "Theoretical error rate:  0.26\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.012597389208722307\n",
      "Mean error:  0.2518181818181818\n",
      "Theoretical error rate:  0.26\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.004942412165787957\n",
      "Mean error:  0.26272727272727275\n",
      "Theoretical error rate:  0.26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_2_a(10, 0.2)\n",
    "task_2_a(100, 0.2)\n",
    "task_2_a(1000, 0.2)\n",
    "task_2_a(10000, 0.2)\n",
    "\n",
    "task_2_a(10, 0.5)\n",
    "task_2_a(100, 0.5)\n",
    "task_2_a(1000, 0.5)\n",
    "task_2_a(10000, 0.5)\n",
    "\n",
    "task_2_a(10, 0.6)\n",
    "task_2_a(100, 0.6)\n",
    "task_2_a(1000, 0.6)\n",
    "task_2_a(10000, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size:  10\n",
      "Standard deviation of the error:  0.14826824027545538\n",
      "Mean error:  0.6727272727272727\n",
      "Theoretical error rate:  0.66\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.05032128182944746\n",
      "Mean error:  0.6663636363636365\n",
      "Theoretical error rate:  0.66\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.012294593315493941\n",
      "Mean error:  0.6675454545454546\n",
      "Theoretical error rate:  0.66\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.003720770381440516\n",
      "Mean error:  0.6604636363636364\n",
      "Theoretical error rate:  0.66\n",
      "\n",
      "Test set size:  10\n",
      "Standard deviation of the error:  0.098752549920002\n",
      "Mean error:  0.7545454545454544\n",
      "Theoretical error rate:  0.75\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.03916483496097822\n",
      "Mean error:  0.7545454545454544\n",
      "Theoretical error rate:  0.75\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.01943414393311997\n",
      "Mean error:  0.7486363636363635\n",
      "Theoretical error rate:  0.75\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.0035335932125437875\n",
      "Mean error:  0.7516909090909091\n",
      "Theoretical error rate:  0.75\n",
      "\n",
      "Test set size:  10\n",
      "Standard deviation of the error:  0.1724878723728207\n",
      "Mean error:  0.7454545454545454\n",
      "Theoretical error rate:  0.74\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.04979295977319692\n",
      "Mean error:  0.7345454545454545\n",
      "Theoretical error rate:  0.74\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.014025949975929368\n",
      "Mean error:  0.7420000000000001\n",
      "Theoretical error rate:  0.74\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.003093635161488294\n",
      "Mean error:  0.7414818181818181\n",
      "Theoretical error rate:  0.74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_2_b(10, 0.2)\n",
    "task_2_b(100, 0.2)\n",
    "task_2_b(1000, 0.2)\n",
    "task_2_b(10000, 0.2)\n",
    "\n",
    "task_2_b(10, 0.5)\n",
    "task_2_b(100, 0.5)\n",
    "task_2_b(1000, 0.5)\n",
    "task_2_b(10000, 0.5)\n",
    "\n",
    "task_2_b(10, 0.6)\n",
    "task_2_b(100, 0.6)\n",
    "task_2_b(1000, 0.6)\n",
    "task_2_b(10000, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size:  10\n",
      "Standard deviation of the error:  0.18497263590341642\n",
      "Mean error:  0.4818181818181818\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.049991734854063705\n",
      "Mean error:  0.500909090909091\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.011827967976211351\n",
      "Mean error:  0.5059090909090909\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.0015329440157330928\n",
      "Mean error:  0.49970909090909094\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  10\n",
      "Standard deviation of the error:  0.1553455226421369\n",
      "Mean error:  0.4636363636363636\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.05954371961386479\n",
      "Mean error:  0.49999999999999994\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.01893442359022885\n",
      "Mean error:  0.4938181818181819\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.004373152502476596\n",
      "Mean error:  0.5006090909090909\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  10\n",
      "Standard deviation of the error:  0.15587661999529315\n",
      "Mean error:  0.5545454545454546\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.05640760748177662\n",
      "Mean error:  0.4799999999999999\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.006141580274201655\n",
      "Mean error:  0.4969090909090909\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.004243147124559922\n",
      "Mean error:  0.49785454545454555\n",
      "Theoretical error rate:  0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_3_c(10, 0.2)\n",
    "task_3_c(100, 0.2)\n",
    "task_3_c(1000, 0.2)\n",
    "task_3_c(10000, 0.2)\n",
    "\n",
    "task_3_c(10, 0.5)\n",
    "task_3_c(100, 0.5)\n",
    "task_3_c(1000, 0.5)\n",
    "task_3_c(10000, 0.5)\n",
    "\n",
    "task_3_c(10, 0.6)\n",
    "task_3_c(100, 0.6)\n",
    "task_3_c(1000, 0.6)\n",
    "task_3_c(10000, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size:  10\n",
      "Standard deviation of the error:  0.13726971700492271\n",
      "Mean error:  0.4454545454545454\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.07254522670276364\n",
      "Mean error:  0.520909090909091\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.011602222642577332\n",
      "Mean error:  0.5035454545454544\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.002851503880440161\n",
      "Mean error:  0.5002272727272726\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  10\n",
      "Standard deviation of the error:  0.07820295697311479\n",
      "Mean error:  0.4454545454545454\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.02742382387090611\n",
      "Mean error:  0.5054545454545455\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.014585739667664886\n",
      "Mean error:  0.49172727272727274\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.0038539450647334813\n",
      "Mean error:  0.49912727272727275\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  10\n",
      "Standard deviation of the error:  0.14937887931959073\n",
      "Mean error:  0.43636363636363634\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  100\n",
      "Standard deviation of the error:  0.04767312946227964\n",
      "Mean error:  0.5\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  1000\n",
      "Standard deviation of the error:  0.021340606542535428\n",
      "Mean error:  0.4921818181818182\n",
      "Theoretical error rate:  0.5\n",
      "\n",
      "Test set size:  10000\n",
      "Standard deviation of the error:  0.004761258948729788\n",
      "Mean error:  0.4995636363636363\n",
      "Theoretical error rate:  0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_3_d(10, 0.2)\n",
    "task_3_d(100, 0.2)\n",
    "task_3_d(1000, 0.2)\n",
    "task_3_d(10000, 0.2)\n",
    "\n",
    "task_3_d(10, 0.5)\n",
    "task_3_d(100, 0.5)\n",
    "task_3_d(1000, 0.5)\n",
    "task_3_d(10000, 0.5)\n",
    "\n",
    "task_3_d(10, 0.6)\n",
    "task_3_d(100, 0.6)\n",
    "task_3_d(1000, 0.6)\n",
    "task_3_d(10000, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task4(N):\n",
    "    results = np.zeros(N)\n",
    "    training_set = np.zeros(2)\n",
    "    z = np.random.random(1)\n",
    "    training_set[1] = cumulative_1_inv(z) #Y = 1\n",
    "    z = np.random.random(1)\n",
    "    training_set[0] = cumulative_2_inv(z) #Y = 0\n",
    "    \n",
    "    data = create_data(N)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(data):\n",
    "        if abs(training_set[1]-data[0][i]) < abs(training_set[0] - data[0][i]):\n",
    "            results[i] = 1\n",
    "            i = i + 1\n",
    "        else:\n",
    "            results[i] = 0\n",
    "            i = i + 1\n",
    "    return error_rate(results, data[1]), training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def many_errors(N):\n",
    "    i = 0\n",
    "    z = np.zeros(100)\n",
    "    while i < 100:\n",
    "        z[i] = task4(N)\n",
    "        i = i + 1\n",
    "    mean = np.mean(z)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5073, array([0.98715878, 0.53926432]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
